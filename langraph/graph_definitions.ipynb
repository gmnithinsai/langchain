{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0f752f",
   "metadata": {},
   "source": [
    "# Langgraph\n",
    "---\n",
    "\n",
    "## Core Design\n",
    "\n",
    "At its core, LangGraph models agent workflows as state machines. You define the behavior of your agents using three key components:\n",
    "\n",
    "- State: A shared data structure that represents the current snapshot of your application. It can be any Python type, but is typically a TypedDict or Pydantic BaseModel.\n",
    "\n",
    "- Nodes: Python functions that encode the logic of your agents. They receive the current State as input, perform some computation or side-effect, and return an updated State.\n",
    "\n",
    "- Edges: Control flow rules that determine which Node to execute next based on the current State. They can be conditional branches or fixed transitions.\n",
    "\n",
    "By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State.\n",
    "\n",
    "##### Or in short: nodes do the work. edges tell what to do next.\n",
    "\n",
    "## Graph Definitions\n",
    "\n",
    "Graphs are the core abstraction of LangGraph. Each StateGraph implementation is used to create graph workflows. Once compiled, you can run the CompiledGraph to run the application.\n",
    "\n",
    "### StateGraph \n",
    "\n",
    "A graph whose nodes communicate by reading and writing to a shared state.Each state key can optionally be annotated with a reducer function that will be used to aggregate the values of that key received from multiple nodes. \n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "- state_schema – The schema class that defines the state.\n",
    "- config_schema – The schema class that defines the configuration. Use this to expose configurable parameters in your API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e438a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langgraph.graph import StateGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203693a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(a: list, b: int | None) -> int:\n",
    "    if b is not None:\n",
    "        return a + [b]\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221614bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    x: Annotated[list, reducer]\n",
    "        \n",
    "class ConfigSchema(TypedDict):\n",
    "    r: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b92b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State, config_schema=ConfigSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121e9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node(state: State, config: RunnableConfig) -> dict:\n",
    "    r = config[\"configurable\"].get(\"r\", 1.0)\n",
    "    x = state[\"x\"][-1]\n",
    "    next_value = x * r * (1 - x)\n",
    "    return {\"x\": next_value}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40021ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"A\", node)\n",
    "graph.set_entry_point(\"A\")\n",
    "graph.set_finish_point(\"A\")\n",
    "compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f945f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConfigurableFieldSpec(id='r', annotation=<class 'float'>, name=None, description=None, default=None, is_shared=False, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(compiled.config_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd35eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = compiled.invoke({\"x\": 0.5}, {\"configurable\": {\"r\": 4.0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d5462e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [0.5, 1.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318660f",
   "metadata": {},
   "source": [
    "add_conditional_edges(source, path, path_map=None, then=None) \n",
    "- Add a conditional edge from the starting node to any number of destination nodes. \n",
    "\n",
    "set_entry_point(key) \n",
    "- Specifies the first node to be called in the graph.\n",
    "\n",
    "set_conditional_entry_point(path, path_map=None, then=None) \n",
    "- Sets a conditional entry point in the graph.\n",
    "\n",
    "set_finish_point(key) \n",
    "- Marks a node as a finish point of the graph. If the graph reaches this node, it will cease execution.\n",
    "\n",
    "add_edge(start_key, end_key) \n",
    "- Adds a directed edge from the start node to the end node.\n",
    "- If the graph transitions to the start_key node, it will always transition to the end_key node next.\n",
    "\n",
    "compile(checkpointer=None, interrupt_before=None, interrupt_after=None, debug=False)\n",
    "- Compiles the state graph into a CompiledGraph object.\n",
    "- The compiled graph implements the Runnable interface and can be invoked, streamed, batched, and run asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076bbc1",
   "metadata": {},
   "source": [
    "### MessageGraph\n",
    "\n",
    "- A StateGraph where every node receives a list of messages as input and returns one or more messages as output.\n",
    "- MessageGraph is a subclass of StateGraph whose entire state is a single, append-only* list of messages.\n",
    "- Each node in a MessageGraph takes a list of messages as input and returns zero or more messages as output. \n",
    "- The add_messages function is used to merge the output messages from each node into the existing list of messages in the graph's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8ddd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import MessageGraph\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c309bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi there.', id='45fea036-a188-4a41-b5eb-387c391715b0'), AIMessage(content='Hello!', id='d5b0ab43-d0fd-431b-a9d9-3c1ef53df0df')]\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple Chatbot Response\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"chatbot\", lambda state: [(\"assistant\", \"Hello!\")])\n",
    "builder.set_entry_point(\"chatbot\")\n",
    "builder.set_finish_point(\"chatbot\")\n",
    "response = builder.compile().invoke([(\"user\", \"Hi there.\")])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12800113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi there. Can you search for X?', id='5592b299-1a47-498e-b251-e6b67701b920'), AIMessage(content='Hello!', id='b32db576-1fcb-4bc1-8360-dbf04b9e5619', tool_calls=[{'name': 'search', 'args': {'query': 'X'}, 'id': '123'}]), ToolMessage(content='Searching...', id='cb63df34-d5bf-4a05-8d71-3cd66261a9c9', tool_call_id='123')]\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Chatbot with Tool Call\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\n",
    "    \"chatbot\",\n",
    "    lambda state: [\n",
    "        AIMessage(\n",
    "            content=\"Hello!\",\n",
    "            tool_calls=[{\"name\": \"search\", \"id\": \"123\", \"args\": {\"query\": \"X\"}}],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "builder.add_node(\n",
    "    \"search\",\n",
    "    lambda state: [ToolMessage(content=\"Searching...\", tool_call_id=\"123\")]\n",
    ")\n",
    "builder.set_entry_point(\"chatbot\")\n",
    "builder.add_edge(\"chatbot\", \"search\")\n",
    "builder.set_finish_point(\"search\")\n",
    "response = builder.compile().invoke([HumanMessage(content=\"Hi there. Can you search for X?\")])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c7a53",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "The following constants and classes are used to help control graph execution.\n",
    "\n",
    "#### START\n",
    "\n",
    "- START is a string constant (\"__start__\") that serves as a \"virtual\" node in the graph. Adding an edge (or conditional edges) from START to node one or more nodes in your graph will direct the graph to begin execution there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5685a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START\n",
    "# builder.add_edge(START, \"my_node\")\n",
    "# Or to add a conditional starting point\n",
    "# builder.add_conditional_edges(START, my_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22076310",
   "metadata": {},
   "source": [
    "#### END\n",
    "- END is a string constant (\"__end__\") that serves as a \"virtual\" node in the graph. Adding an edge (or conditional edges) from one or more nodes in your graph to the END \"node\" will direct the graph to cease execution as soon as it reaches this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b928afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n",
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "builder.add_edge(\"my_node\", END) # Stop any time my_node completes\n",
    "# Or to conditionally terminate\n",
    "def my_condition(state):\n",
    "    if state[\"should_stop\"]:\n",
    "        return END\n",
    "    return \"my_node\"\n",
    "builder.add_conditional_edges(\"my_node\", my_condition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9a115",
   "metadata": {},
   "source": [
    "### Send\n",
    "- A message or packet to send to a specific node in the graph.\n",
    "\n",
    "- The Send class is used within a StateGraph's conditional edges to dynamically route states to different nodes based on certain conditions. This enables creating \"map-reduce\" like workflows, where a node can be invoked multiple times in parallel on different states, and the results can be aggregated back into the main graph's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca8e7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc906bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the OverallState TypedDict with annotated jokes list\n",
    "class OverallState(TypedDict):\n",
    "    subjects: list[str]\n",
    "    jokes: Annotated[list[str], operator.add]\n",
    "\n",
    "# Define the function to continue to jokes based on the state\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state['subjects']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "040482f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph with OverallState\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# Add a node that generates a joke based on the subject in the state\n",
    "builder.add_node(\"generate_joke\", lambda state: {\"jokes\": [f\"Joke about {state['subject']}\"]})\n",
    "\n",
    "# Add conditional edges from START to continue_to_jokes function\n",
    "builder.add_conditional_edges(START, continue_to_jokes)\n",
    "\n",
    "# Add an edge from \"generate_joke\" to END\n",
    "builder.add_edge(\"generate_joke\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f79612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# Invoke the graph with initial state\n",
    "result = graph.invoke({\"subjects\": [\"cats\", \"dogs\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01420491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subjects': ['cats', 'dogs'], 'jokes': ['Joke about cats', 'Joke about dogs']}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a9cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
